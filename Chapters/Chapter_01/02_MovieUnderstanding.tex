\section{Movie understanding}
\label{sec:movieUnderstanding}
In recent years, the field of movie understanding has undergone significant transformations, progressing beyond conventional tasks like clustering individuals and identifying characters~\cite{buffy, knock_knock, face_body_voice, brown2021corroborative, c1c, nagrani2017sherlock} to delve into the intricate analysis of storytelling. Many exciting areas have emerged, each contributing to a more comprehensive understanding of the cinematic experience.

The scope of movie understanding encompasses various dimensions, ranging from scene detection~\cite{local2global_sceneseg, chen2021shotcol, rotman2017osg,  rasheed2003scenedet, tapaswi2014storygraphs} and question-answering to tasks~\cite{movieqa, tvqa, yu2018jsfusion} like movie captioning~\cite{lsmdc, yu2017concepts} with named entities~\cite{fillin}, modeling interactions and/or relationships~\cite{fan2019understanding, marin2019laeo, lirec}, aligning text and video storylines~\cite{book2movie, book_movie_uoft, graph_movienet}, and even tackling the complexities of long-form video understanding~\cite{lvu}. These diverse areas collectively strive to unravel the richness embedded within cinematic narratives.

The advancements in this field owe much to the availability of robust datasets that have fueled research and innovation. Datasets like Condensed Movies~\cite{condensed_movies}, MovieNet~\cite{movienet}, VALUE benchmark (which extends beyond traditional movies)~\cite{value_benchmark}, and MovieGraphs~\cite{moviegraphs} have played pivotal roles in propelling research forward. These datasets provide researchers with the necessary tools to explore and push the boundaries of what can be achieved in the realm of movie understanding.

Building on the foundations laid by MovieGraphs~\cite{moviegraphs}, we focus on another pillar of story understanding complementary to the above directions: identifying the emotions and mental states of each character and the overall scene in a movie.

