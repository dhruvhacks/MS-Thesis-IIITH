\section{Visual emotion recognition}
\label{sec:visualEmoRecog}
The domain of visual emotion recognition has evolved significantly, initially rooted in the identification of Ekman's classic six emotions~\cite{Ekman1971} predominantly through facial expressions. This foundation gained traction with influential datasets like MMI~\cite{pantic2005}, CK, and CK+~\cite{tian2001CK, lucey2010CKplus}, marking a paradigm shift in our understanding of emotional cues in images.

Around a decade ago, benchmark challenges like EmotiW~\cite{DhallEmotiW13}, FER~\cite{fer13}, and AFEW~\cite{afew} emerged as crucial benchmarks for in-the-wild emotion recognition. Simultaneously, deep learning approaches~\cite{Liu2014DeeplyLD, Liu2014FacialER} were introduced to emotion recognition, showcasing notable performance improvements. These benchmarks still focused on classic emotion label sets. Breaking away from this trend, the Emotic dataset~\cite{emotic} introduced the use of 26 labels for emotion understanding in images while highlighting the importance of context for emotion understanding in images.

Moving beyond isolated facial features, the field explored novel directions, including the combination of face features and contextual information. Two-stream Convolutional Neural Networks (CNNs)~\cite{caer} and methods incorporating person detections with depth maps~\cite{emoticon} gained attention for their potential in capturing nuanced emotional states. Recognizing the importance of context, particularly in dynamic scenarios, became a pivotal focus in enhancing the robustness of emotion recognition systems.

Recent trends in emotion recognition have expanded the scope beyond discrete labels to include estimating continuous variables such as valence and arousal. Approaches have emerged to predict emotional states from faces with limited contextual information, and researchers have explored learning representations through webly supervised data to overcome biases~\cite{PandaDE} inherent in existing datasets or improving them further through a joint text-vision embedding space~\cite{WeiEmotionNet}.

In contrast to the prevailing trends in visual emotion recognition, our work EmoTx~\cite{dhruv2023emotx} takes a distinctive approach by concentrating on multi-label emotions and mental states recognition in movies. Exploiting the rich multimodal context available in cinematic scenes and character interactions, our focus extends beyond single facial expressions to capture the complexity and diversity of emotional experiences in a cinematic context.
